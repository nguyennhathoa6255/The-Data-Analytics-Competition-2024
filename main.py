import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
import streamlit as st
from sklearn.preprocessing import OneHotEncoder,LabelBinarizer
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import f1_score, roc_auc_score

from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier

from itertools import combinations

warnings.filterwarnings("ignore")
# Thi·∫øt l·∫≠p page
st.set_page_config(     
    page_title="ƒê·ªòI COPILOT",      
    page_icon="üßä"  
)

# Thi·∫øt l·∫≠p ti√™u ƒë·ªÅ
st.subheader('ƒê√°nh gi√° c√°c ch·ªâ s·ªë c·ªßa c√°c m√¥ h√¨nh h·ªçc m√°y')

df1 = pd.read_csv("dataset/train_1.csv")
df2 = pd.read_csv("dataset/train_2.csv")
df_predict = pd.read_csv("dataset/predict.csv")

df_train = pd.merge(df1, df2, on='Case_ID', how='inner')

df = pd.concat([df_train, df_predict])

# DATA CLEANING-----------------
# Danh s√°ch c√°c bi·∫øn kh√¥ng c·∫ßn thi·∫øt c·∫ßn lo·∫°i b·ªè
unnecessary_columns = ['pct_tl_open_L6M', 'pct_tl_closed_L6M', 'pct_active_tl', 'pct_closed_tl','pct_tl_open_L12M',
                       'pct_tl_closed_L12M','pct_of_active_TLs_ever', 'pct_opened_TLs_L6m_of_L12m', 'pct_currentBal_all_TL',
                       'pct_PL_enq_L6m_of_L12m', 'pct_CC_enq_L6m_of_L12m', 'pct_PL_enq_L6m_of_ever', 'pct_CC_enq_L6m_of_ever']

# Lo·∫°i b·ªè c√°c bi·∫øn kh√¥ng c·∫ßn thi·∫øt t·ª´ dataframe
df = df.drop(columns=unnecessary_columns)

# Thay -99999 th√†nh Nan
df.replace(-99999, np.nan, inplace=True)

# ƒêi·ªÅn Nan l√† trung b√¨nh c·ªßa c·ªôt ƒë√≥
numeric_columns = df.select_dtypes(include=[np.number]).columns # Nh·ªØng c·ªôt c√≥ ki·ªÉu d·ªØ li·ªáu l√† int, float
non_numeric_columns = df.columns.difference(numeric_columns)# Nh·ªØng c·ªôt c√≥ ki·ªÉu d·ªØ li·ªáu l√† object

df_numeric = df[numeric_columns]
df_non_numeric = df[non_numeric_columns]

# Th·ª±c hi·ªán t√≠nh to√°n trung b√¨nh ch·ªâ tr√™n c√°c c·ªôt c√≥ th·ªÉ t√≠nh trung b√¨nh
df = df_numeric.fillna(df_numeric.mean())

# G·∫Øn l·∫°i c√°c c·ªôt kh√¥ng th·ªÉ t√≠nh trung b√¨nh v√†o DataFrame
df[non_numeric_columns] = df_non_numeric

# mapping 2 bi·∫øn MARITALSTATUS v√† GENDER th√†nh s·ªë
MARITALSTATUS_mapping = {'Married': 1, 'Single': 0}
df["MARITALSTATUS"] = df["MARITALSTATUS"].map(MARITALSTATUS_mapping)

GENDER_mapping = {'M': 1, 'F': 0}
df["GENDER"] = df["GENDER"].map(GENDER_mapping)

# one hot encoder 3  bi·∫øn [ 'EDUCATION', 'last_prod_enq2' , 'first_prod_enq2' ]
df = pd.get_dummies(df, columns=[ 'EDUCATION', 'last_prod_enq2', 'first_prod_enq2'])

df.replace(True, 1, inplace=True)
df.replace(False, 0, inplace=True)

# mapping nh√£n th√†nh s·ªë
category_mapping = {'P1': 0, 'P2': 1, 'P3': 2, 'P4': 3}
df["Approved_Flag"] = df["Approved_Flag"].map(category_mapping)

# MODEL-----------------

x = df.drop("Approved_Flag",axis = 1)
y  = df["Approved_Flag"]

scaler = MinMaxScaler()
# Chu·∫©n h√≥a t·ª´ng c·ªôt
for column in x.columns:
    x[column] = scaler.fit_transform(x[[column]])

x_train, x_test, y_train, y_test = train_test_split(x[:len(df_train)],y[:len(df_train)], test_size = 0.2, random_state = 15, stratify = y[:len(df_train)])

x_predict = x[len(df_train):]

@st.cache_data # L∆∞u d·ªØ li·ªáu khi ƒë∆∞·ª£c t·∫£i l√™n streamlit

# H√†m ƒë√°nh gi√°
def EvaluateModel( y_test, y_pred):
    # V·∫Ω confusion matrix
    display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred), display_labels=[0, 1, 2,3])
    fig, ax = plt.subplots()
    display.plot(cmap='Blues', ax=ax)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()
    # st.pyplot(fig)

    # T√≠nh nh·ªØng th√¥ng s·ªë chung
    # st.write('Classification Report: \n', classification_report(y_test, y_pred))
    
    label_binarizer = LabelBinarizer()
    label_binarizer.fit(y_test)
    y_true_onehot = label_binarizer.transform(y_test)
    y_pred_onehot = label_binarizer.transform(y_pred)

    auc_score = roc_auc_score(y_true_onehot, y_pred_onehot, average='micro', multi_class="ovr")
    accuracy = accuracy_score(y_test, y_pred)
    f1score = f1_score(y_test, y_pred, average='micro')    

    st.write('Accuracy: %.3f' % accuracy)
    st.write('F1-Score: %.3f' % f1score)
    st.write('AUC: %.3f' % auc_score)
    metric = 0.3 * accuracy + 0.3 * f1score + 0.4*auc_score
    st.write('**Metric : %.3f** ' % metric)

# T·∫°o select box ƒë·ªÉ ch·ªçn m√¥ h√¨nh
# select_model = st.selectbox('Select Model', ['Logistic Regression', 'Neural Network', 'Random Forest', 'XGBoost', 'LGBM', 'Combined Model'])
options = st.multiselect(
    "Select Model",
    ["Logistic Regression", "Neural Network", "Random Forest", "XGBoost", "LGBM"],
    ["Logistic Regression"])

@st.cache_data
# K·∫øt h·ª£p 3 m√¥ h√¨nh c√≥ ch·ªâ s·ªë Metric cao nh·∫•t 
def CombinedModel(options):
    model_reg = LogisticRegression()
    model_RDF = RandomForestClassifier()
    model_lgbm = LGBMClassifier()
    model_xgb = XGBClassifier()
    model_neural = MLPClassifier()
    models = {
        "Logistic Regression": model_reg,
        "Neural Network": model_neural,
        "Random Forest": model_RDF,
        "XGBoost": model_xgb,
        "LGBM": model_lgbm
    }
    selected_models = [(option, models[option]) for option in options]
    model_combined = VotingClassifier(estimators=selected_models, voting='soft')
    model_combined.fit(x_train, y_train)
    y_pred_combined = model_combined.predict(x_test)
    return y_pred_combined
st.subheader(f'K·∫øt qu·∫£ c√°c ch·ªâ s·ªë ƒë√°nh gi√° c·ªßa m√¥ h√¨nh: {options}')
st.write(EvaluateModel(y_test, CombinedModel(options)))
